# vLLM OpenAI-compatible server image extended to include the app
FROM vllm/vllm-openai:latest

# System deps for audio (soundfile) and git for VCS installs
RUN apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
      libsndfile1 git && \
    rm -rf /var/lib/apt/lists/*

# Ensure transformers/timm compatibility required for newer models
RUN pip install -U -q git+https://github.com/huggingface/transformers.git && \
    pip install -U -q git+https://github.com/huggingface/pytorch-image-models.git && \
    pip install "timm>=1.0.16"

# Install audio extras for vLLM (if not already present in base). Keep uv if available.
RUN pip install "vllm[audio]==0.10.1"

# App directory and Python deps
WORKDIR /app

# Copy only requirements first for better layer caching; requires build context at repo root
COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r /app/requirements.txt

# Copy app source (including the local vllm client wrapper)
COPY app.py /app/app.py
COPY vllm_client /app/vllm_client

# Defaults (override in compose/env)
ENV HF_HOME=/data/hf \
    HUGGINGFACE_HUB_CACHE=/data/hf \
    TRANSFORMERS_CACHE=/data/hf \
    VLLM_LOGGING_LEVEL=INFO \
    VLLM_BASE_URL=http://127.0.0.1:9000/v1

# Expose both the vLLM API and the app server
EXPOSE 8000 9000

# Add the startup script that launches vLLM and the app together
COPY vllm_client/start.sh /app/start.sh
RUN chmod +x /app/start.sh

# Start both services; any extra args passed to the container are forwarded to vLLM
ENTRYPOINT ["/app/start.sh"]
